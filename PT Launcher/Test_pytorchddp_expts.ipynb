{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59894994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (2.86.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: attrs==20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: boto3>=1.20.21 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.21.42)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (3.19.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (1.19.2)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker) (3.7.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.20.21->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.20.21->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.42 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.20.21->sagemaker) (1.24.42)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.25.0,>=1.24.42->boto3>=1.20.21->sagemaker) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c45f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::570106654206:role/Dev\n",
      "sagemaker bucket: sagemaker-us-west-2-570106654206\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "#Add instructions for local environment later, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d850590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file\u001b[39;49;00m\n",
      "\u001b[37m# except in compliance with the License. A copy of the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"LICENSE.txt\" file accompanying this file. This file is distributed on an \"AS IS\"\u001b[39;49;00m\n",
      "\u001b[37m# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express or implied. See the License for\u001b[39;49;00m\n",
      "\u001b[37m# the specific language governing permissions and limitations under the License.\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlr_scheduler\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StepLR\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mparallel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DistributedDataParallel \u001b[34mas\u001b[39;49;00m DDP\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msmdistributed\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdataparallel\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtorch_smddp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Backend\n",
      "\u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33mFor EC2 conda env, in controller node run 'source /shared/pytorch_env/bin/activate', then launch the training using:\u001b[39;49;00m\n",
      "\u001b[33m/opt/amazon/openmpi/bin/mpirun --hostfile /shared/hostfile -N 1 --tag-output --bind-to none --oversubscribe \\\u001b[39;49;00m\n",
      "\u001b[33m--allow-run-as-root --mca btl_tcp_if_exclude lo,docker0 -x PATH -x LD_LIBRARY_PATH -x RDMAV_FORK_SAFE=1 \\\u001b[39;49;00m\n",
      "\u001b[33m-x NCCL_DEBUG=INFO -x FI_EFA_USE_DEVICE_RDMA=1 sh -c ' /shared/pytorch_env/bin/python \\\u001b[39;49;00m\n",
      "\u001b[33m-m torch.distributed.launch --nproc_per_node=8 --nnodes=`wc -l < /shared/hostname` --node_rank=$OMPI_COMM_WORLD_RANK \\\u001b[39;49;00m\n",
      "\u001b[33m--master_addr=`head -n 1 /shared/hostfile` --master_port=12358 /shared/ddp_mnist.py --data_loader_workers=8'\u001b[39;49;00m\n",
      "\u001b[33m'''\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m32\u001b[39;49;00m, \u001b[34m64\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.dropout1 = nn.Dropout2d(\u001b[34m0.25\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.dropout2 = nn.Dropout2d(\u001b[34m0.5\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m9216\u001b[39;49;00m, \u001b[34m128\u001b[39;49;00m)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m128\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        x = \u001b[36mself\u001b[39;49;00m.conv1(x)\n",
      "        x = F.relu(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.conv2(x)\n",
      "        x = F.relu(x)\n",
      "        x = F.max_pool2d(x, \u001b[34m2\u001b[39;49;00m)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.dropout1(x)\n",
      "        x = torch.flatten(x, \u001b[34m1\u001b[39;49;00m)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc1(x)\n",
      "        x = F.relu(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.dropout2(x)\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc2(x)\n",
      "        output = F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\n",
      "        \u001b[34mreturn\u001b[39;49;00m output\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args, model, device, train_loader, optimizer, epoch, rank):\n",
      "    model.train()\n",
      "    train_loader.sampler.set_epoch(epoch)\n",
      "    \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader):\n",
      "        data, target = data.to(device), target.to(device)\n",
      "        optimizer.zero_grad()\n",
      "        output = model(data)\n",
      "        loss = F.nll_loss(output, target)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "        \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)]\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mLoss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "                epoch,\n",
      "                batch_idx * \u001b[36mlen\u001b[39;49;00m(data) * args.world_size,\n",
      "                \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\n",
      "                \u001b[34m100.\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader), loss.item()))\n",
      "        \u001b[34mif\u001b[39;49;00m args.verbose:\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mBatch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, batch_idx, \u001b[33m\"\u001b[39;49;00m\u001b[33mfrom rank\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, rank)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, device, test_loader):\n",
      "    model.eval()\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\n",
      "            data, target = data.to(device), target.to(device)\n",
      "            output = model(data)\n",
      "            test_loss += F.nll_loss(\n",
      "                output, target, reduction=\u001b[33m'\u001b[39;49;00m\u001b[33msum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\n",
      "            pred = output.argmax(\n",
      "                dim=\u001b[34m1\u001b[39;49;00m,\n",
      "                keepdim=\u001b[34mTrue\u001b[39;49;00m)  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\n",
      "            test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\n",
      "            \u001b[34m100.\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)))\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    \u001b[37m# Training settings\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser(description=\u001b[33m'\u001b[39;49;00m\u001b[33mPyTorch MNIST Example\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m64\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m1000\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m14\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 14)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\n",
      "                        default=\u001b[34m1.0\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mlearning rate (default: 1.0)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--gamma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\n",
      "                        default=\u001b[34m0.7\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mLearning rate step gamma (default: 0.7)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=\u001b[34m1\u001b[39;49;00m,\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--local_rank\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "                        default=os.getenv(\u001b[33m'\u001b[39;49;00m\u001b[33mLOCAL_RANK\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m),\n",
      "                        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\n",
      "        metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        help=\u001b[33m'\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--save-model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        action=\u001b[33m'\u001b[39;49;00m\u001b[33mstore_true\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        default=\u001b[34mFalse\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mFor Saving the current Model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33m--verbose\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        action=\u001b[33m'\u001b[39;49;00m\u001b[33mstore_true\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        default=\u001b[34mFalse\u001b[39;49;00m,\n",
      "        help=\u001b[33m'\u001b[39;49;00m\u001b[33mFor displaying smdistributed.dataparallel-specific logs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33m--data_loader_workers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\n",
      "        default=\u001b[34m0\u001b[39;49;00m,\n",
      "        help=\u001b[33m'\u001b[39;49;00m\u001b[33mFor displaying smdistributed.dataparallel-specific logs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=\u001b[33m'\u001b[39;49;00m\u001b[33m/tmp/data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mPath for downloading \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mthe MNIST dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    args = parser.parse_args()\n",
      "    args.world_size = \u001b[36mint\u001b[39;49;00m(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    args.lr = \u001b[34m1.0\u001b[39;49;00m\n",
      "    args.batch_size //= args.world_size // \u001b[34m8\u001b[39;49;00m\n",
      "    args.batch_size = \u001b[36mmax\u001b[39;49;00m(args.batch_size, \u001b[34m1\u001b[39;49;00m)\n",
      "    data_path = args.data_path\n",
      "    dist.init_process_group(backend=\u001b[33m'\u001b[39;49;00m\u001b[33msmddp\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    rank = dist.get_rank()\n",
      "    local_rank = args.local_rank\n",
      "    torch.cuda.set_device(local_rank)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.verbose:\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mHello from rank\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, rank, \u001b[33m'\u001b[39;49;00m\u001b[33mof local_rank\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, local_rank,\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33min world size of\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, args.world_size)\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m torch.cuda.is_available():\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mMust run smdistributed.dataparallel MNIST example on CUDA-capable devices.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "        )\n",
      "    torch.manual_seed(args.seed)\n",
      "    device = torch.device(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mcuda:\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mlocal_rank\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m# select a single rank per node to download data\u001b[39;49;00m\n",
      "    is_first_local_rank = (local_rank == \u001b[34m0\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m is_first_local_rank:\n",
      "        train_dataset = datasets.MNIST(data_path,\n",
      "                                       train=\u001b[34mTrue\u001b[39;49;00m,\n",
      "                                       download=\u001b[34mTrue\u001b[39;49;00m,\n",
      "                                       transform=transforms.Compose([\n",
      "                                           transforms.ToTensor(),\n",
      "                                           transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m, ),\n",
      "                                                                (\u001b[34m0.3081\u001b[39;49;00m, ))\n",
      "                                       ]))\n",
      "    dist.barrier()  \u001b[37m# prevent other ranks from accessing the data early\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m is_first_local_rank:\n",
      "        train_dataset = datasets.MNIST(data_path,\n",
      "                                       train=\u001b[34mTrue\u001b[39;49;00m,\n",
      "                                       download=\u001b[34mFalse\u001b[39;49;00m,\n",
      "                                       transform=transforms.Compose([\n",
      "                                           transforms.ToTensor(),\n",
      "                                           transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m, ),\n",
      "                                                                (\u001b[34m0.3081\u001b[39;49;00m, ))\n",
      "                                       ]))\n",
      "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
      "        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    train_loader = torch.utils.data.DataLoader(\n",
      "        train_dataset,\n",
      "        batch_size=args.batch_size,\n",
      "        shuffle=\u001b[34mFalse\u001b[39;49;00m,\n",
      "        num_workers=args.data_loader_workers,\n",
      "        pin_memory=\u001b[34mTrue\u001b[39;49;00m,\n",
      "        sampler=train_sampler)\n",
      "    \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "        test_loader = torch.utils.data.DataLoader(\n",
      "            datasets.MNIST(data_path,\n",
      "                           train=\u001b[34mFalse\u001b[39;49;00m,\n",
      "                           transform=transforms.Compose([\n",
      "                               transforms.ToTensor(),\n",
      "                               transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m, ), (\u001b[34m0.3081\u001b[39;49;00m, ))\n",
      "                           ])),\n",
      "            batch_size=args.test_batch_size,\n",
      "            shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    model = Net()\n",
      "    model = model.to(device)\n",
      "    model = DDP(model, device_ids=[local_rank])\n",
      "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
      "    scheduler = StepLR(optimizer, step_size=\u001b[34m1\u001b[39;49;00m, gamma=args.gamma)\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        train(args, model, device, train_loader, optimizer, epoch, rank)\n",
      "        \u001b[34mif\u001b[39;49;00m rank == \u001b[34m0\u001b[39;49;00m:\n",
      "            test(model, device, test_loader)\n",
      "        scheduler.step()\n",
      "    \u001b[34mif\u001b[39;49;00m args.save_model:\n",
      "        torch.save(model.state_dict(), \u001b[33m\"\u001b[39;49;00m\u001b[33mmnist_cnn.pt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/train_ptddp_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "584638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_account_id = 763104351884  # By default, set the account ID used for most regions\n",
    "region = \"us-west-2\"\n",
    "image = (\n",
    "    \"ptddp_image\"  # Example: pt-smdataparallel-efficientnet-sagemaker\n",
    ")\n",
    "tag = \"latest\"  # Example: latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9867ac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mARG\u001b[39;49;00m region\n",
      "\n",
      "\u001b[37m# Download base PT DLC. Note that this notebook requires a SM DLC with >= PT 1.10.2\u001b[39;49;00m\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33m763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.11.0-gpu-py38-cu113-ubuntu20.04-sagemaker\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mWORK_DIR\u001b[39;49;00m=\u001b[33m\"ptddp_build\"\u001b[39;49;00m\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m $WORK_DIR\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m pwd; pip install git+https://github.com/vishwakaria/sagemaker-pytorch-training-toolkit/; \u001b[36mecho\u001b[39;49;00m \u001b[33m\"installed pt toolkit\"\u001b[39;49;00m; \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[36mcd\u001b[39;49;00m sagemaker-pytorch-training-toolkit; \u001b[33m\\\u001b[39;49;00m\n",
      "    python setup.py; \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[36mcd\u001b[39;49;00m ..; pip install git+https://github.com/vishwakaria/sagemaker-python-sdk/; \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[36mcd\u001b[39;49;00m sagemaker-python-sdk; \u001b[33m\\\u001b[39;49;00m\n",
      "    python setup.py; \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[36mcd\u001b[39;49;00m ../..; rm -rf \u001b[31m$WORK_DIR\u001b[39;49;00m;\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb3da9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env bash\u001b[39;49;00m\n",
      "\u001b[37m# This script shows how to build the Docker image and push it to ECR to be ready for use\u001b[39;49;00m\n",
      "\u001b[37m# by SageMaker.\u001b[39;49;00m\n",
      "\u001b[37m# The argument to this script is the image name. This will be used as the image on the local\u001b[39;49;00m\n",
      "\u001b[37m# machine and combined with the account and region to form the repository name for ECR.\u001b[39;49;00m\n",
      "\u001b[37m# set region\u001b[39;49;00m\n",
      "\n",
      "\u001b[31mDIR\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[34m$(\u001b[39;49;00m \u001b[36mcd\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[34m$(\u001b[39;49;00m dirname \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mBASH_SOURCE\u001b[39;49;00m[0]\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m && \u001b[36mpwd\u001b[39;49;00m \u001b[34m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mDir: \u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mDIR\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[37m#cd ${DIR}/deberta\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[33m\"\u001b[39;49;00m\u001b[31m$#\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m -eq \u001b[34m3\u001b[39;49;00m ]; \u001b[34mthen\u001b[39;49;00m\n",
      "    \u001b[31mregion\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\n",
      "    \u001b[31mimage\u001b[39;49;00m=\u001b[31m$2\u001b[39;49;00m\n",
      "    \u001b[31mtag\u001b[39;49;00m=\u001b[31m$3\u001b[39;49;00m\n",
      "\u001b[34melse\u001b[39;49;00m\n",
      "    \u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33musage: \u001b[39;49;00m\u001b[31m$0\u001b[39;49;00m\u001b[33m <aws-region> \u001b[39;49;00m\u001b[31m$1\u001b[39;49;00m\u001b[33m <image-repo> \u001b[39;49;00m\u001b[31m$2\u001b[39;49;00m\u001b[33m <image-tag>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \u001b[36mexit\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\n",
      "\u001b[34mfi\u001b[39;49;00m\n",
      "\u001b[37m# Get the account number associated with the current IAM credentials\u001b[39;49;00m\n",
      "\u001b[31maccount\u001b[39;49;00m=\u001b[34m$(\u001b[39;49;00maws sts get-caller-identity --query Account --output text\u001b[34m)\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[31m$?\u001b[39;49;00m -ne \u001b[34m0\u001b[39;49;00m ]\n",
      "\u001b[34mthen\u001b[39;49;00m\n",
      "    \u001b[36mexit\u001b[39;49;00m \u001b[34m255\u001b[39;49;00m\n",
      "\u001b[34mfi\u001b[39;49;00m\n",
      "\n",
      "\u001b[31mfullname\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31maccount\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m.dkr.ecr.\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m.amazonaws.com/\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m:\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mtag\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[37m# If the repository doesn't exist in ECR, create it.\u001b[39;49;00m\n",
      "aws ecr describe-repositories --region \u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m --repository-names \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m > /dev/null \u001b[34m2\u001b[39;49;00m>&\u001b[34m1\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[31m$?\u001b[39;49;00m -ne \u001b[34m0\u001b[39;49;00m ]; \u001b[34mthen\u001b[39;49;00m\n",
      "    \u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcreating ECR repository : \u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mfullname\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    aws ecr create-repository --region \u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m --repository-name \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m > /dev/null\n",
      "\u001b[34mfi\u001b[39;49;00m\n",
      "\u001b[37m# Build the docker image locally with the image name and then push it to ECR\u001b[39;49;00m\n",
      "\u001b[37m# with the full name.\u001b[39;49;00m\n",
      "\u001b[37m# login ECR for the current account\u001b[39;49;00m\n",
      "\n",
      "aws ecr get-login-password --region \u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m | docker login --username AWS --password-stdin \u001b[33m${\u001b[39;49;00m\u001b[31maccount\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m.dkr.ecr.\u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m.amazonaws.com\n",
      "\n",
      "ls \u001b[33m${\u001b[39;49;00m\u001b[31mDIR\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\n",
      "docker build . -t \u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m -f \u001b[33m${\u001b[39;49;00m\u001b[31mDIR\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m/Dockerfile  --build-arg \u001b[31mregion\u001b[39;49;00m=\u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\n",
      "ls\n",
      "docker tag \u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mfullname\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\n",
      "docker push \u001b[33m${\u001b[39;49;00m\u001b[31mfullname\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[31m$?\u001b[39;49;00m -eq \u001b[34m0\u001b[39;49;00m ]; \u001b[34mthen\u001b[39;49;00m\n",
      "\t\u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mAmazon ECR URI: \u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mfullname\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[34melse\u001b[39;49;00m\n",
      "\t\u001b[36mecho\u001b[39;49;00m \u001b[33m\"Error: Image build and push failed\"\u001b[39;49;00m\n",
      "\t\u001b[36mexit\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\n",
      "\u001b[34mfi\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker system prune -af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb536525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "region = \"us-west-2\"\n",
    "# image = (\n",
    "#     \"ptddp_image\"  # Example: pt-smdataparallel-efficientnet-sagemaker\n",
    "# )\n",
    "! aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin 570106654206.dkr.ecr.{region}.amazonaws.com\n",
    "#! chmod +x build_and_push.sh\n",
    "#! bash build_and_push.sh {region} {image} {tag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cd4c0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# refer https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-training-containers to get the right uri's based on region\n",
    "#image_uri = '763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.9.1-transformers4.12.3-gpu-py38-cu111-ubuntu20.04'\n",
    "image_uri = '570106654206.dkr.ecr.us-west-2.amazonaws.com/ptddp-launcher:latest'\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "# this is the only line of code change required to leverage SageMaker Distributed Data Parallel\n",
    "distribution = {'pytorchddp':{ 'enabled': True }}\n",
    "#distribution = {\"mpi\":{\"enabled\":True, \"num_of_processes_per_host\":8}}\n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    base_job_name=\"ptddp-mnist-test\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"train_ptddp_mnist.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.11.0\",\n",
    "    py_version=\"py38\",\n",
    "    image_uri=image_uri,\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    instance_count=1,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    sagemaker_session=sess,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    distribution=distribution,\n",
    "    debugger_hook_config=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3117378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-28 05:41:08 Starting - Starting the training job...ProfilerReport-1656394868: InProgress\n",
      "...\n",
      "2022-06-28 05:41:51 Starting - Preparing the instances for training..........................................\n",
      "2022-06-28 05:49:10 Downloading - Downloading input data\n",
      "2022-06-28 05:49:10 Training - Downloading the training image...........................\n",
      "2022-06-28 05:53:36 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34msed: can't read changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.c: No such file or directory\u001b[0m\n",
      "\u001b[34mgcc: fatal error: no input files\u001b[0m\n",
      "\u001b[34mcompilation terminated.\u001b[0m\n",
      "\u001b[34mgcc: error: changehostname.o: No such file or directory\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:38,979 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:39,060 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:39,065 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:39,695 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"ptddp-mnist-test-2022-06-28-05-41-08-016\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-570106654206/ptddp-mnist-test-2022-06-28-05-41-08-016/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ptddp_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ptddp_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ptddp_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ptddp_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-570106654206/ptddp-mnist-test-2022-06-28-05-41-08-016/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"ptddp-mnist-test-2022-06-28-05-41-08-016\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-570106654206/ptddp-mnist-test-2022-06-28-05-41-08-016/source/sourcedir.tar.gz\",\"module_name\":\"train_ptddp_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ptddp_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220430-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train_ptddp_mnist.py\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mERROR: ld.so: object '/libchangehostname.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train_ptddp_mnist.py\", line 244, in <module>\u001b[0m\n",
      "\u001b[34mmain()\n",
      "  File \"train_ptddp_mnist.py\", line 169, in main\n",
      "    args.world_size = int(os.environ['WORLD_SIZE'])\u001b[0m\n",
      "\u001b[34mFile \"/opt/conda/lib/python3.8/os.py\", line 675, in __getitem__\u001b[0m\n",
      "\u001b[34mraise KeyError(key) from None\u001b[0m\n",
      "\u001b[34mKeyError: 'WORLD_SIZE'\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:42,762 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:42,762 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"raise KeyError(key) from None\n",
      " KeyError: 'WORLD_SIZE'\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 train_ptddp_mnist.py\"\u001b[0m\n",
      "\u001b[34m2022-06-28 05:53:42,762 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-06-28 05:54:11 Uploading - Uploading generated training model\n",
      "2022-06-28 05:54:11 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job ptddp-mnist-test-2022-06-28-05-41-08-016: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"raise KeyError(key) from None\n KeyError: 'WORLD_SIZE'\"\nCommand \"/opt/conda/bin/python3.8 train_ptddp_mnist.py\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-28be9b2c12b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3337\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m             )\n\u001b[1;32m   3341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job ptddp-mnist-test-2022-06-28-05-41-08-016: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"raise KeyError(key) from None\n KeyError: 'WORLD_SIZE'\"\nCommand \"/opt/conda/bin/python3.8 train_ptddp_mnist.py\", exit code: 1"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "744742fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "region = \"us-west-2\"\n",
    "! aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin 570106654206.dkr.ecr.{region}.amazonaws.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a396dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test if normal docker container works with this script\n",
    "# image: PT training DLC (without any code changes)\n",
    "# distribution = smdistributed, backend = nccl\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# refer https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-training-containers to get the right uri's based on region\n",
    "image_uri = '763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.11.0-gpu-py38-cu113-ubuntu20.04-sagemaker'\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "# this is the only line of code change required to leverage SageMaker Distributed Data Parallel\n",
    "distribution = { \"smdistributed\": { \"dataparallel\": { \"enabled\": True } } }\n",
    "#distribution = {\"mpi\":{\"enabled\":True, \"num_of_processes_per_host\":8}}\n",
    "\n",
    "\n",
    "estimator_pt_base = PyTorch(\n",
    "    base_job_name=\"ptddp-mnist-test\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"train_ptddp_mnist.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.11.0\",\n",
    "    py_version=\"py38\",\n",
    "    image_uri=image_uri,\n",
    "    # For training with multinode distributed training, set this count. Example: 2\n",
    "    instance_count=1,\n",
    "    # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    sagemaker_session=sess,\n",
    "    # Training using SMDataParallel Distributed Training Framework\n",
    "    distribution=distribution,\n",
    "    debugger_hook_config=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8c13b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-29 00:18:47 Starting - Starting the training job...ProfilerReport-1656461927: InProgress\n",
      "...\n",
      "2022-06-29 00:19:35 Starting - Preparing the instances for training.............................................\n",
      "2022-06-29 00:27:13 Downloading - Downloading input data\n",
      "2022-06-29 00:27:13 Training - Downloading the training image.....................\n",
      "2022-06-29 00:30:51 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:No exception classes found in smdistributed.dataparallel\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_pytorch_container.training:Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_pytorch_container.training:Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_pytorch_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Creating SSH daemon.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Network interface name: eth0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Host: ['algo-1']\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:instance type: ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p4d.24xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"ptddp-mnist-test-2022-06-29-00-18-47-140\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-570106654206/ptddp-mnist-test-2022-06-29-00-18-47-140/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ptddp_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ptddp_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ptddp_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ptddp_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-570106654206/ptddp-mnist-test-2022-06-29-00-18-47-140/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"ptddp-mnist-test-2022-06-29-00-18-47-140\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-570106654206/ptddp-mnist-test-2022-06-29-00-18-47-140/source/sourcedir.tar.gz\",\"module_name\":\"train_ptddp_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ptddp_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x FI_EFA_USE_DEVICE_RDMA=1 smddprun /opt/conda/bin/python3.8 -m mpi4py train_ptddp_mnist.py\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/9912422 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▌         | 590848/9912422 [00:00<00:01, 5503482.44it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 2071552/9912422 [00:00<00:00, 10798737.96it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 3737600/9912422 [00:00<00:00, 12512534.92it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▎    | 5323776/9912422 [00:00<00:00, 13004873.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 69%|██████▉   | 6880256/9912422 [00:00<00:00, 13854647.00it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 8682496/9912422 [00:00<00:00, 14338971.71it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#0159913344it [00:00, 13691193.09it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Extracting /tmp/data/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#01529696it [00:00, 1123708.09it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Extracting /tmp/data/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 24%|██▎       | 391168/1648877 [00:00<00:00, 3896587.16it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#0151649664it [00:00, 10050450.31it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Extracting /tmp/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#0155120it [00:00, 39841997.18it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Extracting /tmp/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/data/MNIST/raw\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Bootstrap : Using eth0:10.0.195.98<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:122 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:119 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:729 [2] NCCL INFO comm 0x7f2210002fb0 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:122:731 [4] NCCL INFO comm 0x7fc3ac002fb0 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:732 [5] NCCL INFO comm 0x7ff738002fb0 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:730 [6] NCCL INFO comm 0x7fc0a0002fb0 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:728 [0] NCCL INFO comm 0x7f5760002fb0 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:734 [7] NCCL INFO comm 0x7f87b0002fb0 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:735 [1] NCCL INFO comm 0x7fb1b4002fb0 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:119:733 [3] NCCL INFO comm 0x7facc8002fb0 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [0/60000 (0%)]#011Loss: 2.305867\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [5120/60000 (8%)]#011Loss: 1.718472\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [10240/60000 (17%)]#011Loss: 1.404571\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [15360/60000 (25%)]#011Loss: 1.039781\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [20480/60000 (34%)]#011Loss: 1.601454\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [25600/60000 (42%)]#011Loss: 1.377890\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [30720/60000 (51%)]#011Loss: 1.303451\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [35840/60000 (59%)]#011Loss: 1.232950\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [40960/60000 (68%)]#011Loss: 1.167727\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [46080/60000 (76%)]#011Loss: 1.088704\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [51200/60000 (85%)]#011Loss: 1.373645\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [56320/60000 (93%)]#011Loss: 1.406892\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.1570, Accuracy: 9724/10000 (97%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [0/60000 (0%)]#011Loss: 1.088924\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [5120/60000 (8%)]#011Loss: 1.273102\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [10240/60000 (17%)]#011Loss: 1.022876\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [15360/60000 (25%)]#011Loss: 1.402310\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [20480/60000 (34%)]#011Loss: 1.190121\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [25600/60000 (42%)]#011Loss: 1.154701\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [30720/60000 (51%)]#011Loss: 1.181283\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [35840/60000 (59%)]#011Loss: 1.129982\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [40960/60000 (68%)]#011Loss: 1.154591\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [46080/60000 (76%)]#011Loss: 1.115936\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [51200/60000 (85%)]#011Loss: 1.248148\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [56320/60000 (93%)]#011Loss: 1.189071\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.1124, Accuracy: 9843/10000 (98%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [0/60000 (0%)]#011Loss: 1.089919\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [5120/60000 (8%)]#011Loss: 1.010326\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [10240/60000 (17%)]#011Loss: 1.093030\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [15360/60000 (25%)]#011Loss: 1.235356\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [20480/60000 (34%)]#011Loss: 1.100412\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [25600/60000 (42%)]#011Loss: 0.976529\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [30720/60000 (51%)]#011Loss: 1.018237\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [35840/60000 (59%)]#011Loss: 1.239659\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [40960/60000 (68%)]#011Loss: 1.318428\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [46080/60000 (76%)]#011Loss: 1.295880\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [51200/60000 (85%)]#011Loss: 1.149908\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [56320/60000 (93%)]#011Loss: 1.075570\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.1273, Accuracy: 9829/10000 (98%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [0/60000 (0%)]#011Loss: 0.927175\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [5120/60000 (8%)]#011Loss: 0.972258\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [10240/60000 (17%)]#011Loss: 0.831236\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [15360/60000 (25%)]#011Loss: 0.945528\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [20480/60000 (34%)]#011Loss: 1.214547\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [25600/60000 (42%)]#011Loss: 0.822298\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [30720/60000 (51%)]#011Loss: 1.258646\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [35840/60000 (59%)]#011Loss: 1.220758\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [40960/60000 (68%)]#011Loss: 1.044963\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [46080/60000 (76%)]#011Loss: 1.246029\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [51200/60000 (85%)]#011Loss: 1.338375\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [56320/60000 (93%)]#011Loss: 1.486517\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0823, Accuracy: 9855/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [0/60000 (0%)]#011Loss: 1.245252\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [5120/60000 (8%)]#011Loss: 1.441794\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [10240/60000 (17%)]#011Loss: 1.343053\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [15360/60000 (25%)]#011Loss: 1.268867\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [20480/60000 (34%)]#011Loss: 1.225565\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [25600/60000 (42%)]#011Loss: 0.916402\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [30720/60000 (51%)]#011Loss: 1.006607\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [35840/60000 (59%)]#011Loss: 1.305265\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [40960/60000 (68%)]#011Loss: 0.956853\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [46080/60000 (76%)]#011Loss: 1.198134\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [51200/60000 (85%)]#011Loss: 1.028537\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [56320/60000 (93%)]#011Loss: 0.938844\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0695, Accuracy: 9881/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [0/60000 (0%)]#011Loss: 1.437265\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [5120/60000 (8%)]#011Loss: 1.050900\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [10240/60000 (17%)]#011Loss: 1.052543\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [15360/60000 (25%)]#011Loss: 1.125443\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [20480/60000 (34%)]#011Loss: 1.236772\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [25600/60000 (42%)]#011Loss: 1.005832\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [30720/60000 (51%)]#011Loss: 1.177001\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [35840/60000 (59%)]#011Loss: 0.861180\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [40960/60000 (68%)]#011Loss: 1.199028\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [46080/60000 (76%)]#011Loss: 1.404619\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [51200/60000 (85%)]#011Loss: 1.123657\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [56320/60000 (93%)]#011Loss: 1.313122\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0645, Accuracy: 9884/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [0/60000 (0%)]#011Loss: 1.162099\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [5120/60000 (8%)]#011Loss: 1.265124\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [10240/60000 (17%)]#011Loss: 1.161321\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [15360/60000 (25%)]#011Loss: 1.238266\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [20480/60000 (34%)]#011Loss: 1.119609\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [25600/60000 (42%)]#011Loss: 1.078679\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [30720/60000 (51%)]#011Loss: 1.325018\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [35840/60000 (59%)]#011Loss: 1.295362\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [40960/60000 (68%)]#011Loss: 1.124600\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [46080/60000 (76%)]#011Loss: 0.687173\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [51200/60000 (85%)]#011Loss: 1.269752\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [56320/60000 (93%)]#011Loss: 1.055112\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0611, Accuracy: 9890/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [0/60000 (0%)]#011Loss: 0.900477\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [5120/60000 (8%)]#011Loss: 1.261611\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [10240/60000 (17%)]#011Loss: 1.082882\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [15360/60000 (25%)]#011Loss: 1.337692\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [20480/60000 (34%)]#011Loss: 1.136360\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [25600/60000 (42%)]#011Loss: 1.537951\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [30720/60000 (51%)]#011Loss: 1.087323\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [35840/60000 (59%)]#011Loss: 1.051588\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [40960/60000 (68%)]#011Loss: 1.055818\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [46080/60000 (76%)]#011Loss: 1.259623\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [51200/60000 (85%)]#011Loss: 1.391747\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [56320/60000 (93%)]#011Loss: 1.233806\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0637, Accuracy: 9888/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [0/60000 (0%)]#011Loss: 1.333887\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [5120/60000 (8%)]#011Loss: 1.193184\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [10240/60000 (17%)]#011Loss: 1.277943\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [15360/60000 (25%)]#011Loss: 1.119341\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [20480/60000 (34%)]#011Loss: 1.220478\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [25600/60000 (42%)]#011Loss: 1.086717\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [30720/60000 (51%)]#011Loss: 1.296594\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [35840/60000 (59%)]#011Loss: 1.275145\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [40960/60000 (68%)]#011Loss: 1.045362\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [46080/60000 (76%)]#011Loss: 1.267905\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [51200/60000 (85%)]#011Loss: 1.450603\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [56320/60000 (93%)]#011Loss: 1.183062\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0607, Accuracy: 9887/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [0/60000 (0%)]#011Loss: 1.197683\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [5120/60000 (8%)]#011Loss: 1.133531\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [10240/60000 (17%)]#011Loss: 1.269880\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [15360/60000 (25%)]#011Loss: 1.439478\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [20480/60000 (34%)]#011Loss: 1.044460\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [25600/60000 (42%)]#011Loss: 1.233402\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [30720/60000 (51%)]#011Loss: 1.108533\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [35840/60000 (59%)]#011Loss: 1.028827\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [40960/60000 (68%)]#011Loss: 1.372223\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [46080/60000 (76%)]#011Loss: 1.250638\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [51200/60000 (85%)]#011Loss: 1.189924\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [56320/60000 (93%)]#011Loss: 1.016841\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0589, Accuracy: 9886/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [0/60000 (0%)]#011Loss: 1.153307\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [5120/60000 (8%)]#011Loss: 1.004356\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [10240/60000 (17%)]#011Loss: 1.086620\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [15360/60000 (25%)]#011Loss: 0.971208\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [20480/60000 (34%)]#011Loss: 1.059914\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [25600/60000 (42%)]#011Loss: 1.398083\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [30720/60000 (51%)]#011Loss: 1.105854\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [35840/60000 (59%)]#011Loss: 1.440048\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [40960/60000 (68%)]#011Loss: 1.015833\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [46080/60000 (76%)]#011Loss: 0.967749\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [51200/60000 (85%)]#011Loss: 1.414715\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [56320/60000 (93%)]#011Loss: 1.050538\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0578, Accuracy: 9891/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [0/60000 (0%)]#011Loss: 0.852025\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [5120/60000 (8%)]#011Loss: 1.488291\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [10240/60000 (17%)]#011Loss: 1.118990\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [15360/60000 (25%)]#011Loss: 1.233523\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [20480/60000 (34%)]#011Loss: 0.860512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [25600/60000 (42%)]#011Loss: 1.046351\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [30720/60000 (51%)]#011Loss: 0.978814\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [35840/60000 (59%)]#011Loss: 1.193146\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [40960/60000 (68%)]#011Loss: 0.870928\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [46080/60000 (76%)]#011Loss: 0.868806\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [51200/60000 (85%)]#011Loss: 1.190222\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [56320/60000 (93%)]#011Loss: 1.190562\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0571, Accuracy: 9888/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [0/60000 (0%)]#011Loss: 1.328951\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [5120/60000 (8%)]#011Loss: 1.296908\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [10240/60000 (17%)]#011Loss: 1.122905\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [15360/60000 (25%)]#011Loss: 1.465140\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [20480/60000 (34%)]#011Loss: 1.164544\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [25600/60000 (42%)]#011Loss: 1.315442\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [30720/60000 (51%)]#011Loss: 1.323412\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [35840/60000 (59%)]#011Loss: 1.446233\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [40960/60000 (68%)]#011Loss: 1.043855\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [46080/60000 (76%)]#011Loss: 1.374672\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [51200/60000 (85%)]#011Loss: 1.398448\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [56320/60000 (93%)]#011Loss: 1.163525\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0565, Accuracy: 9892/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [0/60000 (0%)]#011Loss: 1.423929\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [5120/60000 (8%)]#011Loss: 1.068646\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [10240/60000 (17%)]#011Loss: 0.939670\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [15360/60000 (25%)]#011Loss: 1.120085\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [20480/60000 (34%)]#011Loss: 1.186959\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [25600/60000 (42%)]#011Loss: 1.058108\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [30720/60000 (51%)]#011Loss: 1.150213\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [35840/60000 (59%)]#011Loss: 0.979298\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [40960/60000 (68%)]#011Loss: 1.155041\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [46080/60000 (76%)]#011Loss: 1.207950\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [51200/60000 (85%)]#011Loss: 1.085143\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [56320/60000 (93%)]#011Loss: 1.186195\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: 0.0567, Accuracy: 9887/10000 (99%)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-06-29 00:32:14 Uploading - Uploading generated training model\n",
      "2022-06-29 00:32:14 Completed - Training job completed\n",
      "Training seconds: 313\n",
      "Billable seconds: 313\n"
     ]
    }
   ],
   "source": [
    "estimator_pt_base.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0004d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
